{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lec 06-1: Softmax Regression (multinominal classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 다음과 같이 3개의 구분이 필요한 경우, 앞서의 binominal이 3개 필요하다. \n",
    "#####    : 1) if A or not + 2) if B or not + 3) if C or not \n",
    "<left><img src= 'img/multi_classification.PNG' width=\"50%\"></left>\n",
    "\n",
    "##### - 따라서 3개의 행렬계산이 필요하며, 이를 3x3 행렬 하나로 표현할 수 있다. \n",
    "<left><img src= 'img/multi_classification2.PNG' width=\"25%\"></left> <left><img src= 'img/multi_classification3.PNG' width=\"36.5%\"></left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lec 06-2: Cost function of Softmax Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 3개의 행렬연산 결과로 3개의 vector 값을 얻게 되는데, 여기에 softmax를 적용하여 확률로 변환한다. \n",
    "#####  : softmax는 입력값을 sigmoid와 같이 0~1의 값으로 변환하며, 동시에 변환된 값들의 합계가 1이 되도록 한다.\n",
    "<left><img src= 'img/softmax.PNG' width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  - multinominal에서 사용하는 corss entropy cost 함수는, 앞서의 logistic cost 함수와 동일하다. \n",
    "<left><img src= 'img/cross_entropy1.PNG' width=\"40%\"><left><img src= 'img/cross_entropy2.PNG' width=\"36%\">\n",
    "#####  - cost 함수는 아래와 같이 모형의 예측과 실제값간의 distance 평균으로 정의되며, Gradient Descent를 통해 이 값을 최소화 시키는 W를 찾아야 한다. \n",
    "<left><img src= 'img/cost_multi.PNG' width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 6-1 : Softmax Classification with tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\youngboo.choi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2,1,1], \n",
    "          [2,1,3,2], \n",
    "          [3,1,3,4], \n",
    "          [4,1,5,5], \n",
    "          [1,7,5,5], \n",
    "          [1,2,5,6], \n",
    "          [1,6,6,6], \n",
    "          [1,7,7,7]]\n",
    "\n",
    "y_data = [[0,0,1], \n",
    "          [0,0,1], \n",
    "          [0,0,1], \n",
    "          [0,1,0], \n",
    "          [0,1,0], \n",
    "          [0,1,0], \n",
    "          [1,0,0],           \n",
    "          [1,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.76265\n",
      "200 0.65671456\n",
      "400 0.5347403\n",
      "600 0.43684354\n",
      "800 0.34346002\n",
      "1000 0.25807378\n",
      "1200 0.22749545\n",
      "1400 0.20679861\n",
      "1600 0.18943605\n",
      "1800 0.17466685\n",
      "2000 0.16195798\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder('float', [None, 4])\n",
    "Y = tf.placeholder('float', [None, 3])\n",
    "nb_class = 3 \n",
    "#### nb_class : number class, 여기서는 a/b/c의 3종류로 구분하는 문제이므로 클래스가 3임 \n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, nb_class]), name = 'wieght')\n",
    "b = tf.Variable(tf.random_normal([nb_class]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis = 1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "#### graphing \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed = {X:x_data, Y:y_data}\n",
    "    \n",
    "for step in range(2001): \n",
    "    sess.run( optimizer, feed_dict = feed  )\n",
    "    if step % 200 == 0 : \n",
    "        print(step, sess.run(cost, feed_dict = feed) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.9021583e-03 9.9309033e-01 7.5271387e-06]] [1]\n"
     ]
    }
   ],
   "source": [
    "#### 새로운 입력값에 대해서 결과를 예측해보자 \n",
    "#### 계산값과 함께, argument max 명령어로 확률이 가장 높은 값의 위치(0, 1, 2)를 출력한다. \n",
    "new_data = [[1, 11, 7, 9]]\n",
    "\n",
    "a = sess.run(hypothesis, feed_dict = {X:new_data})\n",
    "print(a, sess.run(tf.arg_max(a, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.9021713e-03 9.9309033e-01 7.5271528e-06]\n",
      " [8.4775984e-01 1.4439094e-01 7.8493282e-03]\n",
      " [1.6835154e-08 3.5959345e-04 9.9964035e-01]] [1 0 2]\n"
     ]
    }
   ],
   "source": [
    "new_data2 = [[1, 11, 7, 9], \n",
    "             [1, 3, 4, 3], \n",
    "             [1, 1, 0, 1] ]\n",
    "\n",
    "b = sess.run(hypothesis, feed_dict = {X:new_data2})\n",
    "print(b, sess.run(tf.arg_max(b, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 6-2 : Fancy Softmax Classification with tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'yellow'> - animal classification with softmax_cross_entropy_with_logits </font>\n",
    "##### <font color = 'yellow'> - cross-entropy, one_hot, reshape 함수를 사용하여 코드를 간단하게 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 16)\n",
      "(101, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "xy = np.loadtxt('data/data-04-zoo.txt', delimiter = ',', dtype = np.float32)\n",
    "#xy\n",
    "\n",
    "#### 동물들의 특징을 나타내는 컬럼들과, 맨 마지막 컬럼은 0~6으로 어떤 동물인지 구분 \n",
    "x_data = xy[:, 0 :-1 ] \n",
    "y_data = xy[:, [-1] ] \n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-35-5d01c157bd5c>:17: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "0 6.016442\n",
      "200 0.42918673\n",
      "400 0.25095323\n",
      "600 0.17637682\n",
      "800 0.13502614\n",
      "1000 0.10884621\n",
      "1200 0.0909438\n",
      "1400 0.078030154\n",
      "1600 0.06832586\n",
      "1800 0.060790006\n",
      "2000 0.054778647\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 16])\n",
    "Y = tf.placeholder(tf.int32, [None, 1])\n",
    "nb_class = 7 \n",
    "\n",
    "\n",
    "#### 0~6의 7개 값을 가진 Y를 onehot으로 recoding하고, 이를 다시 reshape하여 원하는 행렬을 만든다. \n",
    "#### onehot은 입력값 n+1개의 값을 만들기 때문에 reshape 과정이 필요하다. \n",
    "Y_one_hot = tf.one_hot(Y, nb_class)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_class])\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random_normal([16, nb_class]), name = 'wieght')\n",
    "b = tf.Variable(tf.random_normal([nb_class]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "#### cost 함수를 softmax_cross_entropy_with_logits를 사용하여 간단하게 ... \n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits = tf.matmul(X, W) + b, labels = Y_one_hot)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "#### graphing \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed = {X:x_data, Y:y_data}\n",
    "    \n",
    "for step in range(2001): \n",
    "    sess.run( optimizer, feed_dict = feed  )\n",
    "    if step % 200 == 0 : \n",
    "        print(step, sess.run(cost, feed_dict = feed) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.018991813 1.0\n",
      "100 0.01869604 1.0\n",
      "200 0.018409608 1.0\n",
      "300 0.018132083 1.0\n",
      "400 0.017863045 1.0\n",
      "500 0.01760204 1.0\n",
      "600 0.01734881 1.0\n",
      "700 0.017102933 1.0\n",
      "800 0.01686416 1.0\n",
      "900 0.016632093 1.0\n",
      "1000 0.016406525 1.0\n",
      "1100 0.016187105 1.0\n",
      "1200 0.015973663 1.0\n",
      "1300 0.015765933 1.0\n",
      "1400 0.015563659 1.0\n",
      "1500 0.015366628 1.0\n",
      "1600 0.015174667 1.0\n",
      "1700 0.014987556 1.0\n",
      "1800 0.014805144 1.0\n",
      "1900 0.0146271745 1.0\n",
      "2000 0.014453549 1.0\n"
     ]
    }
   ],
   "source": [
    "#### 모형의 정확도를 파악해보자 \n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.arg_max(Y_one_hot, 1)) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "for step in range(2001): \n",
    "    sess.run( optimizer, feed_dict = feed)\n",
    "    if step % 100 == 0 : \n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict = feed)\n",
    "        print(step, loss, acc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 3 True_Value: 3\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 3 True_Value: 3\n",
      "True Prediction: 3 True_Value: 3\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 3 True_Value: 3\n",
      "True Prediction: 6 True_Value: 6\n",
      "True Prediction: 6 True_Value: 6\n",
      "True Prediction: 6 True_Value: 6\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 3 True_Value: 3\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 5 True_Value: 5\n",
      "True Prediction: 4 True_Value: 4\n",
      "True Prediction: 4 True_Value: 4\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 5 True_Value: 5\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 3 True_Value: 3\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 3 True_Value: 3\n",
      "True Prediction: 5 True_Value: 5\n",
      "True Prediction: 5 True_Value: 5\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 5 True_Value: 5\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 6 True_Value: 6\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 5 True_Value: 5\n",
      "True Prediction: 4 True_Value: 4\n",
      "True Prediction: 6 True_Value: 6\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 3 True_Value: 3\n",
      "True Prediction: 3 True_Value: 3\n",
      "True Prediction: 2 True_Value: 2\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 6 True_Value: 6\n",
      "True Prediction: 3 True_Value: 3\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 2 True_Value: 2\n",
      "True Prediction: 6 True_Value: 6\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 2 True_Value: 2\n",
      "True Prediction: 6 True_Value: 6\n",
      "True Prediction: 3 True_Value: 3\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 6 True_Value: 6\n",
      "True Prediction: 3 True_Value: 3\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 5 True_Value: 5\n",
      "True Prediction: 4 True_Value: 4\n",
      "True Prediction: 2 True_Value: 2\n",
      "True Prediction: 2 True_Value: 2\n",
      "True Prediction: 3 True_Value: 3\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 1 True_Value: 1\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 5 True_Value: 5\n",
      "True Prediction: 0 True_Value: 0\n",
      "True Prediction: 6 True_Value: 6\n",
      "True Prediction: 1 True_Value: 1\n"
     ]
    }
   ],
   "source": [
    "pred = sess.run(prediction, feed_dict = feed)\n",
    "\n",
    "for p, y in zip(pred, y_data.flatten()): \n",
    "    print(p==int(y), \"Prediction:\", p, \"True_Value:\", int(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
