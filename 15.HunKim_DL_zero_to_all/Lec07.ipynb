{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lec 07-1: Learning rate, Overfitting, and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'yellow'> 1. learning rate을 너무 크지 않게, 그러면서도 작지 않게 조절하는 것은 무척 어렵고, 많은 경험이 필요한 영역이다. </font>\n",
    "- 다양한 learning rate을 사용해서 여러 번에 걸쳐 실행하는 것이 최선\n",
    "- cost가 거꾸로 증가하는 overshooting 현상과 너무 조금씩 감소하는 현상 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'yellow'> 2. 변수들간의 scale이 크게 차이가 날때, 표준화/정규화를 고려해야 한다. </font>\n",
    "\n",
    "<left><img src= 'img/norm.PNG' width=\"20%\"></left>\n",
    "Normalization \n",
    "- 수식 : (요소값 - 최소값) / (최대값 - 최소값)\n",
    "- 설명 : 전체 구간을 0~100으로 설정하여 데이터를 관찰하는 방법으로, 특정 데이터의 위치를 확인할 수 있게 해줌\n",
    "\n",
    "<left><img src= 'img/standa.PNG' width=\"15%\"></left>\n",
    "Standardization\n",
    "- 수식 : (요소값 - 평균) / 표준편차\n",
    "- 설명 : 평균까지의 거리로, 2개 이상의 대상이 단위가 다를 때, 대상 데이터를 같은 기준으로 볼 수 있게 해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'yellow'> 3. Overfitting을 피하기 위해서는 ... </font>\n",
    "- training data가 많을 수록 좋다\n",
    "- 입력으로 들어오는 변수(feature, x)의 갯수를 줄여라\n",
    "- Regularization을 사용해라 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'yellow'> 4. 일반화(Regularization)란? </font>\n",
    "- Regularization은 W(weight)가 너무 큰 값들을 갖지 않도록 하는 것을 말한다. 머신러닝에서는 \"데이터보다 모델의 복잡도(complexity)가 크다\"라고 설명한다. 과도하게 복잡하기 때문에 발생하는 문제라고 보는 것이다. 다시 말하면, Regularization은 모델의 복잡도를 낮추기 위한 방법을 말한다.\n",
    "\n",
    "- Regularization을 구현하는 것은 매우 쉽다. cost 함수가 틀렸을 때 높은 비용이 발생할 수 있도록 벌점(penalty)을 부과하는 것처럼 W에 대한 값이 클 경우에 penalty를 부여하면 된다. W에 대해 제곱을 한 합계를 cost 함수에 더하는 것이 전부다. 다만 합계를 어느 정도로 반영할지 결정할 수 있어야, 사용하는 시점에서 다양한 적용이 가능하다. 람다(λ)라고 부르는 값을 사용해서 얼마나 penalty를 부여할 것인지 결정할 수 있다.\n",
    "\n",
    "<left><img src= 'img/regul.PNG' width=\"40%\"></left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lec 07-1: Training / Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터를 training / test set으로 나눌수도 있으나, 양이 충분하다면 training / validation / test로 나누는 것이 좋다. \n",
    "- validation set은 training된 데이터에 대해 Regularizaion, 즉 적정한 람다를 구하는 과정이다. \n",
    "\n",
    "<left><img src= 'img/tvt.PNG' width=\"40%\"></left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터가 너무 많아도 문제다. 이럴 경우에는 전체를 한번에 처리하지 않고 조금씩 나누어서 처리할 수도 있다. 이것을 online learning이라고 한다. \n",
    "- 데이터가 너무 많거나 신규 데이터가 지속적으로 유입되는 상황에서 사용하는 모델이다.\n",
    "\n",
    "<left><img src= 'img/onlineL.PNG' width=\"25%\"></left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 07-1: training / test dataset, learning_rate, normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\youngboo.choi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### training & test dataset \n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.926218 [[-0.22623351 -0.64901024  0.45830038]\n",
      " [-0.2228286  -2.2120435   1.1979349 ]\n",
      " [ 2.0336921   1.110654   -0.08623518]]\n",
      "20 0.9679497 [[-0.41781768 -0.5196851   0.52055943]\n",
      " [-0.56351465 -1.1386981   0.4652755 ]\n",
      " [ 1.5556706   1.8315243  -0.32908353]]\n",
      "40 0.8503883 [[-0.5158865  -0.57602215  0.6749653 ]\n",
      " [-0.55665696 -0.93496716  0.25468725]\n",
      " [ 1.5650101   1.6364826  -0.143381  ]]\n",
      "60 0.7631129 [[-0.6166944  -0.62071055  0.8204614 ]\n",
      " [-0.5204684  -0.78393257  0.06746406]\n",
      " [ 1.5503998   1.4924849   0.01522661]]\n",
      "80 0.69989777 [[-0.7165198  -0.65519613  0.95477223]\n",
      " [-0.47079122 -0.6748615  -0.09128404]\n",
      " [ 1.5276598   1.3906281   0.13982356]]\n",
      "100 0.65562266 [[-0.8125813  -0.68115944  1.0767971 ]\n",
      " [-0.4209205  -0.59789485 -0.21812147]\n",
      " [ 1.5084162   1.3217628   0.22793224]]\n",
      "120 0.62493503 [[-0.90366334 -0.70018196  1.1869017 ]\n",
      " [-0.37815797 -0.54524446 -0.31353435]\n",
      " [ 1.4979947   1.2776545   0.28246212]]\n",
      "140 0.60281956 [[-0.9897295  -0.7137479   1.2865336 ]\n",
      " [-0.3447095  -0.5101546  -0.38207266]\n",
      " [ 1.4970074   1.250729    0.31037506]]\n",
      "160 0.5856985 [[-1.0713047  -0.7231195   1.3774805 ]\n",
      " [-0.31989086 -0.4869043  -0.4301416 ]\n",
      " [ 1.50385     1.234706    0.3195551 ]]\n",
      "180 0.57150024 [[-1.1490443  -0.72925884  1.4613595 ]\n",
      " [-0.30199462 -0.4712067  -0.4637354 ]\n",
      " [ 1.5164587   1.2251048   0.31654778]]\n",
      "200 0.5591366 [[-1.2235452  -0.73286283  1.5394646 ]\n",
      " [-0.28927693 -0.460189   -0.48747078]\n",
      " [ 1.5330442   1.2190809   0.30598626]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder('float', [None, 3])\n",
    "Y = tf.placeholder('float', [None, 3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b) \n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate= 0.1).minimize(cost)\n",
    "\n",
    "#### correct prediction test model\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y, 1) )\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "#### graphing \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed = {X:x_data, Y:y_data}\n",
    "    \n",
    "for step in range(201): \n",
    "    cost_val, W_val, _ =  sess.run( [cost, W, optimizer], feed_dict = feed  )\n",
    "    if step % 20 == 0 : \n",
    "        print(step, cost_val, W_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2]\n",
      "-----------------------------------------------\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "#### predict & accuracy \n",
    "print(sess.run( prediction , feed_dict = {X: x_test} ))\n",
    "print('-----------------------------------------------')\n",
    "print(sess.run( accuracy , feed_dict = feed ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 07-2: Meet MNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### tf library로 부터 mnist dataset을 블러오는 코드 \n",
    "#### input_data module 실행 불가시, 웹에서 tutorials 폴더를 다운받아 아래 경로에 복사할 것 \n",
    "#### -> C:\\Users\\youngboo.choi\\AppData\\Local\\Continuum\\anaconda3\\Lib\\site-packages\\tensorflow\\examples\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 1개는 28x28로 되어 있고, 1차원으로 늘어 놓으면 784가 되고 이것을 feature라고 부른다. \n",
    "- 이미지 갯수를 모르는 경우에도 처리할 수 있어야 하니까 갯수를 의미하는 행(row) 크기를 None으로 줬다. \n",
    "- feature를 의미하는 열(column) 크기는 앞에서 말한대로 784가 된다. 784픽셀로 이루어진 이미지가 여러 장 있다는 뜻이다. \n",
    "- y는 label의 갯수, 즉 0에서 9까지의 숫자를 판단하기 때문에 10개가 되어야 하고, 이미지 갯수는 모르므로 역시 None으로 처리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "nb_classes = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Epoch은 모든 Dataset이 Neural network 전체에 대한 학습을 1번 수행한 것을 말한다. \n",
    "- Gradient Decendent 는 반복 학습법으로 1 Epoch으로는 변형출제되는 앞으로의 시험을 학습 할수는 없다.(1번만에 책을 달달 암기하는 사람은 없지 않은가?)\n",
    "- Epoch을 1번만 하면 Underfitting이 주로 발생한다. Epoch을 여러번 할수록 최적화 에서 Overfitting으로 순차적으로 변화한다. \n",
    "(반복학습되서 달달 암기를 완료해도 너무 책 하나만 읽으면 응용력이 부족해지는 현상정도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Cost: 2.799827165\n",
      "Epoch: 0002, Cost: 1.124116889\n",
      "Epoch: 0003, Cost: 0.895180857\n",
      "Epoch: 0004, Cost: 0.778963006\n",
      "Epoch: 0005, Cost: 0.704364932\n",
      "Epoch: 0006, Cost: 0.651273374\n",
      "Epoch: 0007, Cost: 0.611816854\n",
      "Epoch: 0008, Cost: 0.579863486\n",
      "Epoch: 0009, Cost: 0.554412914\n",
      "Epoch: 0010, Cost: 0.533000468\n",
      "Epoch: 0011, Cost: 0.514299998\n",
      "Epoch: 0012, Cost: 0.498504491\n",
      "Epoch: 0013, Cost: 0.484422440\n",
      "Epoch: 0014, Cost: 0.472542689\n",
      "Epoch: 0015, Cost: 0.461534454\n",
      "----- Learning finished -----\n",
      "Accuracy:  0.8871\n",
      "Label:  [3]\n",
      "Prediction:  [3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### 파일이 너무 크기때문에 epoch와 batch를 사용한다. \n",
    "num_epochs = 15\n",
    "batch_size = 100\n",
    "num_iterations = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "\n",
    "#### graph \n",
    "with tf.Session() as sess:    \n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val = sess.run([train, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += cost_val / num_iterations\n",
    "\n",
    "        print(\"Epoch: {:04d}, Cost: {:.9f}\".format(epoch + 1, avg_cost))\n",
    "\n",
    "    print(\"----- Learning finished -----\")\n",
    "\n",
    "    \n",
    "# Test the model using test sets\n",
    "    print(\n",
    "        \"Accuracy: \",\n",
    "        accuracy.eval(\n",
    "            session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}\n",
    "        ),\n",
    "    )   \n",
    "    \n",
    "    \n",
    "# Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r : r + 1], 1)))\n",
    "    print(\n",
    "        \"Prediction: \",\n",
    "        sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r : r + 1]}),\n",
    "    )\n",
    "\n",
    "    \n",
    "# 실제 값을 그림으로 출력한다.     \n",
    "    plt.imshow(\n",
    "        mnist.test.images[r : r + 1].reshape(28, 28),\n",
    "        cmap=\"Greys\",\n",
    "        interpolation=\"nearest\",\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
