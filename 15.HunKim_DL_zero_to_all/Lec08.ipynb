{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lec 08-1: 딥러닝의 기본 개념- 시작과 XOR 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 외부의 자극(x)에 가중치(W)와 바이어스(b)가 부여된 값(WX +b)가 뉴런에 입력되고, \n",
    "- 그 값이 특정 임계치 이상인 경우 신경망을 통해 전달된다. \n",
    "\n",
    "<left><img src= 'img/neuron.PNG' width=\"40%\"></left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1차 침체기 : and/or을 linear 방식으로 풀수 있으나, xor은 풀수 없다는것이 증명됨\n",
    "\n",
    "<left><img src= 'img/xor.PNG' width=\"30%\"></left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Backpropagation과 CNN(convolution Neural network)에 대한 아이디어가 나오면서 극복되는 듯 했으나, \n",
    "\n",
    "<left><img src= 'img/backp.PNG' width=\"45%\"></left>\n",
    "- Backpropagation의 한계, layer가 많을 경우 뒤에서부터 멀리 떨어진 layer의 W와 b를 변경할 수 없다는 한계로, 머신러닝 분야의 두 번째 침체기를 맞음 \n",
    "\n",
    "<left><img src= 'img/bigp.PNG' width=\"50%\"></left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lec 08-2: 딥러닝의 기본 개념- Back propagation과 2006/2007 '딥'의 출현 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'yellow'> 새로운 연구결과 </font>\n",
    "- 여러 개의 layer가 있어도 초기값을 잘 선택하면 학습이 가능하다.\n",
    "- 신경망을 잘 구성하면 복잡한 문제를 효율적으로 풀 수 있다.\n",
    "- Neural Network 대신 사람들의 주의를 끌 수 있는 Deep Learning으로 rebranding\n",
    "##### --> ImageNet 경진대회에서 한 대학원생이 AlexNet으로 획기적인 성능 향상으로, 관심을 끌어올림 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'yellow'> 지금까지 neural network가 잘 작동하지 않았던 이유는... </font>\n",
    "- labeled 데이터셋이 너무 작았고,\n",
    "- 컴퓨터는 수백만 배 느렸다.\n",
    "- 초기화를 잘 하지 못했고,\n",
    "- non-linearity(sigmoid)를 잘못 사용했다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 08: Tensor manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'yellow'> 선형대수 기초 : Tensor(arrary)를 자유자재로 다루기  </font>\n",
    "\n",
    "- 1) shape, rank, axix의 개념 \n",
    "- 2) 행렬계산에서 matmul과 multiply의 차이\n",
    "- 3) reduce_mean, reduce_sum, argmax 계산시 axis 지정\n",
    "- 4) reshape, squeeze, expand_dims\n",
    "- 5) one_hot, cast, stack \n",
    "- 6) ones like, zero like\n",
    "- 7) zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (3,)\n",
      "2 (2, 3)\n",
      "3 (2, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "#### rank는 차원의 수, shape는 요소의 수를 의미한다. \n",
    "#### cf.차원의 갯수는 중괄호의 갯수와 같음 \n",
    "\n",
    "x1 = [1., 2., 3.]                  # Rank = 1 , Shape = [3]\n",
    "\n",
    "x2 = [[1., 2., 3.], \n",
    "      [4., 5., 6.]]                # Rank = 2, Shape = [2, 3]\n",
    "\n",
    "x3 = [\n",
    "       [[1., 2., 3.]], \n",
    "       [[7., 8., 9.]]\n",
    "      ]                            # Rank = 3, Shape = [2, 1, 3]\n",
    "\n",
    "print(np.array(x1).ndim, np.array(x1).shape)\n",
    "print(np.array(x2).ndim, np.array(x2).shape)    ### 2x3 matrix \n",
    "print(np.array(x3).ndim, np.array(x3).shape)    ### 2x(1x3) matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2) (2, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.],\n",
       "       [11.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1 = tf.constant( [ [1. , 2.], [3., 4.] ] )\n",
    "matrix2 = tf.constant( [ [1.], [2.] ] )\n",
    "\n",
    "print(matrix1.shape, matrix2.shape)\n",
    "\n",
    "tf.matmul(matrix1, matrix2).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- matrix1, 2 모두 rank=2 이므로, shape는 [  ,  ] 형태가 됨 \n",
    "- matrix1은 2x2 매트릭스, matrix2는 2x1 매트릭스임 \n",
    "- matmul(matrix multiply)의 결과는, 1x1 + 2x2 = 5 & 3x1 + 4x2 = 11 이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [6. 8.]]\n",
      "-------------------------\n",
      "[[2. 3.]\n",
      " [5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "#### 주의! 매트릭스 곱(matmul)과 일반행렬의 곱셈(multiply)는 다르다. \n",
    "#### 일반연산은 broadcasting이 적용되어 shape에 상관없이 계산이 이뤄진다\n",
    "print((matrix1*matrix2).eval())\n",
    "print('-------------------------')\n",
    "print((matrix1+matrix2).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "[2. 3.]\n",
      "[1.5 3.5]\n",
      "[1.5 3.5]\n",
      "---------------------------------------\n",
      "10.0\n",
      "[4. 6.]\n",
      "[3. 7.]\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "#### axis = 0은 컬럼방향(세로), 1은 행방향(가로)으로 연산한다.  \n",
    "#### axis = -1은 가장 안쪽의 것에 대해 세로방향을 의미한다. \n",
    "x = [ [1. , 2.], \n",
    "      [3. , 4.]  ]\n",
    "\n",
    "print( tf.reduce_mean(x).eval() )              ## (1 + 2 + 3 + 4) / 4 = 2.5 \n",
    "print( tf.reduce_mean(x, axis = 0).eval() )    ## (1 + 3) / 2 = 2 , (2 + 4) / 2 = 3 \n",
    "print( tf.reduce_mean(x, axis = 1).eval() )    ## (1 + 2 ) / 2 = 1.5 , (3 + 4) / 2 = 3.5 \n",
    "print( tf.reduce_mean(x, axis = -1).eval() )    ## (1 + 2 ) / 2 = 1.5 , (3 + 4) / 2 = 3.5 \n",
    "\n",
    "print('---------------------------------------')\n",
    "\n",
    "print( tf.reduce_sum(x).eval() )              ## 1 + 2 + 3 + 4 = 10\n",
    "print( tf.reduce_sum(x, axis = 0).eval() )    ## 1 + 3 = 4 , 2 + 4 = 6 \n",
    "print( tf.reduce_sum(x, axis = 1).eval() )    ## 1 + 2 = 3 , 3 + 4 = 7\n",
    "print( tf.reduce_sum(x, axis = -1).eval() )    ## 1 + 2 = 3 , 3 + 4 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0]\n",
      "[2 0]\n",
      "[2 0]\n"
     ]
    }
   ],
   "source": [
    "#### arg_max : 가장 큰 값의 위치(index)를 말하라\n",
    "x2 = [ [0,1,2], \n",
    "       [2,1,0] ]\n",
    "\n",
    "print( tf.argmax(x2, axis = 0).eval() )\n",
    "print( tf.argmax(x2, axis = 1).eval() )\n",
    "print( tf.argmax(x2, axis = -1).eval() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파이썬 NumPy 에서 배열의 차원(Dimension)을 재구조화, 변경하고자 할 때 reshape() 메소드를 사용합니다.  \n",
    "- 가령, 3개의 행과 4개의 열로 구성된 2차원의 배열로 재설정하고 싶으면 reshape(3, 4) 처럼 reshape()의 매개변수로 변경하고자 하는 배열의 행과 열의 차원을 정수로 입력해주면 됩니다. \n",
    "- 그런데 reshape(-1, 2) 혹은 reshape(3, -1) 처럼 reshape() 메소드 안에 '-1'이 들어가 있는 경우가 있습니다. \n",
    "- 이때 reshape()의 '-1'이 의미하는 바는, 변경된 배열의 '-1' 위치의 차원은 \"원래 배열의 길이와 남은 차원으로 부터 추정\"이 된다는 뜻입니다. (알아서 하라는 뜻)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### reshape \n",
    "t = np.array([[[0, 1, 2], \n",
    "               [3, 4, 5]],\n",
    "              \n",
    "              [[6, 7, 8], \n",
    "               [9, 10, 11]]])\n",
    "t.shape   ## [ 2 , 2 , 3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 3,  4,  5],\n",
       "       [ 6,  7,  8],\n",
       "       [ 9, 10, 11]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### n x 3 매트릭스로 reshape 하라 \n",
    "tf.reshape(t, shape=[-1, 3]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2]],\n",
       "\n",
       "       [[ 3,  4,  5]],\n",
       "\n",
       "       [[ 6,  7,  8]],\n",
       "\n",
       "       [[ 9, 10, 11]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### n x (1 x 3) 매트릭스로 reshape 하라 \n",
    "tf.reshape(t, shape = [-1, 1, 3]).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- squeeze는 차원 중 사이즈가 1인 것을 찾아 스칼라값으로 바꿔 해당 차원을 제거한다.\n",
    "- expand_dims는 axis로 지정된 차원을 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze( [[0],[1],[2]] ).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims( [0,1,2], 1 ).eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- one-hot(원핫)인코딩이란? 단 하나의 값만 True이고 나머지는 모두 False인 인코딩을 말한다.\n",
    "- 즉, 1개만 Hot(True)이고 나머지는 Cold(False)이다.\n",
    "- 예를들면 [0, 0, 0, 0, 1]이다. 5번째(Zero-based 인덱스이므로 4)만 1이고 나머지는 0이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0.]],\n",
       "\n",
       "       [[0., 0., 1.]],\n",
       "\n",
       "       [[1., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot([[0], [1], [2], [0]], depth=3).eval()\n",
    "#### 첫번째부터 index = 0이 true, 두번째는 index = 1이 true, .... \n",
    "#### 0~2의 3가지 숫자로 구성되었으므로, depth = 3 이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### one_hot 연산시 rank하나가 증가하기 때문에, 보통 reshape를 통해서 아래와 같이 만들어 준다. \n",
    "t = tf.one_hot([[0], [1], [2], [0]], depth=3)\n",
    "tf.reshape(t, shape=[-1, 3]).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.cast : 텐서를 새로운 형태로 캐스팅하는데 사용한다.\n",
    "- 부동소수점형에서 정수형으로 바꾼 경우 소수점 버림을 한다.\n",
    "- Boolean형태인 경우 True이면 1, False이면 0을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast([1.8, 2.2, 3.3, 4.9], tf.int32).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast([True, False, 1 == 1, 0 == 1], tf.int32).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.stack : 여러 조각의 행렬을 합칠 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4],\n",
       "       [2, 5],\n",
       "       [3, 6]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1, 4]\n",
    "y = [2, 5]\n",
    "z = [3, 6]\n",
    "\n",
    "tf.stack([x, y, z]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 축의 방향을 바꿔서 쌓는다. (앞서 stack의 결과물을 transpose 하는 것)\n",
    "tf.stack([x, y, z], axis = 1).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.ones_like(x) : 매트릭스 x와 동일한 shape로, 1으로 채워진 매트릭스를 만든다. \n",
    "- tf.zeros_like(x) : 매트릭스 x와 동일한 shape로, 0으로 채워진 매트릭스를 만든다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[0, 1, 2],\n",
    "     [2, 1, 0]]\n",
    "\n",
    "tf.ones_like(x).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros_like(x).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- zip() 은 동일한 개수로 이루어진 자료형을 묶어 주는 역할을 하는 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n",
      "2 5\n",
      "3 6\n"
     ]
    }
   ],
   "source": [
    "### 두 매트릭스를 각각 x, y에 할당하여 한번에 처리한다. \n",
    "for x, y in zip([1, 2, 3], [4, 5, 6]):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 7\n",
      "2 5 8\n",
      "3 6 9\n"
     ]
    }
   ],
   "source": [
    "for x, y, z in zip([1, 2, 3], [4, 5, 6], [7, 8, 9]):\n",
    "    print(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
