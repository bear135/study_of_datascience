{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35e6e38-852f-47e7-bcc8-a0a414f18e6e",
   "metadata": {},
   "source": [
    "## 네이버 리뷰 크롤링 version 2.0\n",
    "- 제작자: SCL 디지털기획팀 최영부  \n",
    "- 일자: 2023. 12.14 \n",
    "- 참고자료: https://jinooh.tistory.com/89, Chat GPT 3.5\n",
    "- version 1.0 대비 변경사항 : 사용자가 지정한 날짜 이후의 리뷰 데이터만 가져오도록 코드 수정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8308b218-b9c2-4362-850f-dafd6aadd3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium\n",
    "#!pip install bs4\n",
    "#!pip install requests\n",
    "#!pip install urllib3\n",
    "#!pip install webdriver_manager\n",
    "#!pip install openpyxl\n",
    "#!pip install xlrd\n",
    "#!pip install datetime\n",
    "#!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e771f9a-4dd1-4632-833d-aee1e5be64de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 필요한 패키지 로딩 \n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import selenium\n",
    "import lxml\n",
    "import re\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "from openpyxl import Workbook\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1872d1de-58b6-4bf3-b859-d66b1a67161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>brand</th>\n",
       "      <th>store_type</th>\n",
       "      <th>store_name</th>\n",
       "      <th>store_url_naver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>Chai797</td>\n",
       "      <td>JUCD</td>\n",
       "      <td>Chai797 시청점</td>\n",
       "      <td>https://m.place.naver.com/restaurant/109550077...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>정육점</td>\n",
       "      <td>JUCD</td>\n",
       "      <td>정육점 여의도점</td>\n",
       "      <td>https://m.place.naver.com/restaurant/152704864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>호우섬</td>\n",
       "      <td>CD</td>\n",
       "      <td>호우섬 청량리역점</td>\n",
       "      <td>https://m.place.naver.com/restaurant/191734975...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no    brand store_type    store_name  \\\n",
       "0  20  Chai797       JUCD  Chai797 시청점    \n",
       "1  39      정육점       JUCD      정육점 여의도점   \n",
       "2  50      호우섬         CD     호우섬 청량리역점   \n",
       "\n",
       "                                     store_url_naver  \n",
       "0  https://m.place.naver.com/restaurant/109550077...  \n",
       "1  https://m.place.naver.com/restaurant/152704864...  \n",
       "2  https://m.place.naver.com/restaurant/191734975...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 매장명, url 리스트 로딩 \n",
    "import pandas as pd \n",
    "df = pd.read_excel('data/store_list.xlsx')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7736a55-a911-4273-aebf-339c5ee4b835",
   "metadata": {},
   "source": [
    "---\n",
    "##### - 사용자가 특정 날짜를 지정하면, 해당 일자 이후의 데이터만 가져오게 된다. \n",
    "##### - user_specified_date = \"2023-01-01\"과 같이, 반드시 \"yyyy-mm-dd\"형태로 정확한 날짜를 입력할 것 \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99f74c93-68d0-4d2e-aebb-7edb09dacd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined date in YYYY-MM-DD format : 사용자가 지정한 날짜 이후의 데이터만 가져온다. \n",
    "user_specified_date = \"2023-12-01\"\n",
    "\n",
    "# Convert the user-specified date to a datetime object\n",
    "user_date = datetime.datetime.strptime(user_specified_date, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2be6242-ee4e-407d-b607-f181272d20bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 store_started\n",
      "0 store_finish\n",
      "1 store_started\n",
      "1 store_finish\n",
      "2 store_started\n",
      "2 store_finish\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(df['store_name'])): \n",
    "    url = df['store_url_naver'][x]\n",
    "    s_brand = df['brand'][x]\n",
    "    s_type = df['store_type'][x]\n",
    "    s_store = df['store_name'][x]\n",
    "    \n",
    "    # Webdriver headless mode setting\n",
    "    options = webdriver.ChromeOptions()\n",
    "    #options.add_argument('headless')\n",
    "    options.add_argument('window-size=1920x1080')\n",
    "    options.add_argument(\"disable-gpu\")\n",
    "\n",
    "    # BS4 setting for secondary access\n",
    "    session = requests.Session()\n",
    "    headers = {\n",
    "        \"User-Agent\": \"user value\"}\n",
    "\n",
    "    retries = Retry(total=5,\n",
    "                    backoff_factor=0.1,\n",
    "                    status_forcelist=[500, 502, 503, 504])\n",
    "\n",
    "    session.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "    # New xlsx file\n",
    "    now = datetime.datetime.now()\n",
    "    xlsx = Workbook()\n",
    "    list_sheet = xlsx.create_sheet('output')\n",
    "    list_sheet.append(['brand', 'type','store', 'date', 'nickname', 'content', 'revisit'])\n",
    "\n",
    "    # Start crawling/scraping!\n",
    "    try:        \n",
    "        driver = webdriver.Chrome()        \n",
    "        res = driver.get(url)\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        # Pagedown : 이 부분을 활성화 시키면 전체 리뷰를 가져온다. (비활성화시 첫페이지 10개 리뷰만 가져옴)\n",
    "        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                driver.find_element(By.XPATH, '//*[@id=\"app-root\"]/div/div/div/div[7]/div[2]/div[3]/div[2]/a').click()\n",
    "                time.sleep(0.8)\n",
    "        except Exception as e:\n",
    "            print( str(x) +' '+'store_started')\n",
    "        \n",
    "\n",
    "        time.sleep(20)\n",
    "        html = driver.page_source\n",
    "        bs = BeautifulSoup(html, 'lxml')\n",
    "        reviews = bs.select('li.YeINN')\n",
    "\n",
    "        for r in reviews:             \n",
    "            brand = s_brand\n",
    "            store_type = s_type\n",
    "            store_name = s_store\n",
    "            \n",
    "            ## 해당 매장의 검색결과 화면에서, iframe내 값들을 확인 \n",
    "            nickname = r.select_one('div.VYGLG')\n",
    "            content = r.select_one('div.ZZ4OK.IwhtZ')    \n",
    "            date = r.select('span.tzZTd>span.place_blind')[1]\n",
    "            revisit = r.select('div._7kR3e>span.tzZTd')[1]\n",
    "\n",
    "            # exception handling\n",
    "            nickname = nickname.text if nickname else ''\n",
    "            content = content.text if content else ''\n",
    "            date = date.text if date else ''\n",
    "            revisit = revisit.text if revisit else ''\n",
    "            \n",
    "            # Convert the review date to a datetime object\n",
    "            match = re.search(r'(\\d{4})년 (\\d{1,2})월 (\\d{1,2})일', date)\n",
    "            year, month, day = map(int, match.groups())\n",
    "            formatted_date = f'{year:04d}-{month:02d}-{day:02d}'\n",
    "            review_date = datetime.datetime.strptime(formatted_date, '%Y-%m-%d')\n",
    "\n",
    "            # Check if the review date is after the user-specified date\n",
    "            if review_date >= user_date:\n",
    "                list_sheet.append([brand, store_type, store_name, review_date, nickname, content, revisit])\n",
    "                time.sleep(5)\n",
    "            \n",
    "        # Save the file\n",
    "        # file_name = 'naver_review_' + str(s_store) + '_' + now.strftime('%Y-%m-%d_%H-%M-%S') + '.xlsx'\n",
    "        file_name = 'naver_review_'+ str(s_store) + '.xlsx'\n",
    "        xlsx.save('output/' + file_name)\n",
    "        print( str(x) +' '+'store_finish')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # Save the file(temp)\n",
    "        file_name = 'naver_review_'+ str(s_store) + '.xlsx'\n",
    "        xlsx.save('output/' + file_name)\n",
    "        print( str(x) +' '+'store_finish')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b07a5cc-20f3-4888-afbe-472460b89cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n### 날짜(2023년 10월 4일 수요일)를 timestamp 형태(yyyy-mm-dd)로 변환하여 다시 저장 \\ndf = pd.read_excel('concated_file/naver_review_all.xlsx')\\n\\ndf['date'] = df['date'].replace('년 ','-', regex=True).replace('월 ', '-', regex=True).replace('일 ', '-', regex=True).str[:-4]\\ndf['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d', errors='raise')\\n\\ndf.to_excel('concated_file/naver_review_all.xlsx', index=False)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## output 폴더내 생성된 모든 (매장별)엑셀파일을 하나로 합치기 \n",
    " \n",
    "import glob\n",
    "import datetime as dt\n",
    "\n",
    "try:\n",
    "    path = 'output/'\n",
    "    files = glob.glob(path + \"*.xlsx\")\n",
    "    excel = pd.DataFrame()\n",
    "    for file_name in files:\n",
    "        df = pd.read_excel(file_name, sheet_name='output')\n",
    "        #excel = excel.append(df, ignore_index=True)        ## pandas 2.xx 버전 이후에서는 append가 작동하지 않음 \n",
    "        excel = pd.concat([excel, df], ignore_index=True)\n",
    "    #print(excel)\n",
    "    excel.to_excel('concated_file/naver_review_all.xlsx', index=False)\n",
    "    \n",
    "except Exception as ex:\n",
    "    print('error' + str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568099bb-7d7b-45cd-9eb3-6020f0e182b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
