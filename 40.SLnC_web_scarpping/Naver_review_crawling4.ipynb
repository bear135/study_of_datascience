{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d35e6e38-852f-47e7-bcc8-a0a414f18e6e",
   "metadata": {},
   "source": [
    "## 네이버 리뷰 크롤링 version 3.0\n",
    "- 제작자: SCL 디지털기획팀 최영부  \n",
    "- 일자: 2024. 05.28 \n",
    "- 기존버전 대비 변경사항 : \n",
    "  1) 네이버 플레이스 리뷰의 구조 변경에 따라 코드 수정  \n",
    "  2) 화면배율 50%로 축소(options.add_argument('--force-device-scale-factor=0.5')) \n",
    "     ~ 몇몇 페이지에서 최하단 \"테마리스트\"때문에 \"더보기\" 버튼이 화면에 보이지 않아 클릭할 수 없는 현상 수정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308b218-b9c2-4362-850f-dafd6aadd3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium\n",
    "#!pip install bs4\n",
    "#!pip install requests\n",
    "#!pip install urllib3\n",
    "#!pip install webdriver_manager\n",
    "#!pip install openpyxl\n",
    "#!pip install xlrd\n",
    "#!pip install datetime\n",
    "#!pip install lxml\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e771f9a-4dd1-4632-833d-aee1e5be64de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 필요한 패키지 로딩 \n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import selenium\n",
    "import lxml\n",
    "import re\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "from openpyxl import Workbook\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1872d1de-58b6-4bf3-b859-d66b1a67161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 매장명, url 리스트 로딩 \n",
    "import pandas as pd \n",
    "df = pd.read_excel('data/store_list.xlsx')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7736a55-a911-4273-aebf-339c5ee4b835",
   "metadata": {},
   "source": [
    "---\n",
    "##### - 사용자가 특정 날짜를 지정하면, 해당 일자 이후의 데이터만 가져오게 된다. \n",
    "##### - user_specified_date = \"2024-01-01\"과 같이, 반드시 \"yyyy-mm-dd\"형태로 정확한 날짜를 입력할 것 \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f74c93-68d0-4d2e-aebb-7edb09dacd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined date in YYYY-MM-DD format : 사용자가 지정한 날짜 이후의 데이터만 가져온다. \n",
    "user_specified_date = \"2023-10-19\"\n",
    "\n",
    "# Convert the user-specified date to a datetime object\n",
    "user_date = datetime.datetime.strptime(user_specified_date, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be6242-ee4e-407d-b607-f181272d20bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(df['store_name'])): \n",
    "    url = df['store_url_naver'][x]\n",
    "    s_brand = df['brand'][x]\n",
    "    s_type = df['store_type'][x]\n",
    "    s_store = df['store_name'][x]\n",
    "    \n",
    "    # Webdriver headless mode setting\n",
    "    options = webdriver.ChromeOptions()\n",
    "    #options.add_argument('headless')\n",
    "    options.add_argument('window-size=1920x1080')\n",
    "    options.add_argument('--force-device-scale-factor=0.5') #화면 배율 50%로, 마지막까지 scroll down된 상태에서 \"더보기\"가 보이도록\n",
    "    options.add_argument(\"disable-gpu\")\n",
    "\n",
    "    # BS4 setting for secondary access\n",
    "    session = requests.Session()\n",
    "    headers = {\n",
    "        \"User-Agent\": \"user value\"}\n",
    "\n",
    "    retries = Retry(total=5,\n",
    "                    backoff_factor=0.1,\n",
    "                    status_forcelist=[500, 502, 503, 504])\n",
    "\n",
    "    session.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "    # New xlsx file\n",
    "    now = datetime.datetime.now()\n",
    "    xlsx = Workbook()\n",
    "    list_sheet = xlsx.create_sheet('output')\n",
    "    list_sheet.append(['brand', 'type','store', 'date', 'nickname', 'content', 'revisit'])\n",
    "\n",
    "    # Start crawling/scraping!\n",
    "    try:        \n",
    "        driver = webdriver.Chrome(options=options)        \n",
    "        res = driver.get(url)\n",
    "        driver.implicitly_wait(5)\n",
    "\n",
    "        while True: \n",
    "            driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(1) \n",
    "            end_of_page = driver.execute_script(\"return window.scrollY + window.innerHeight >= document.body.scrollHeight\")\n",
    "            if end_of_page: \n",
    "                break \n",
    "\n",
    "        try:\n",
    "            while True:                \n",
    "                driver.find_element(By.XPATH, '//*[@id=\"app-root\"]/div/div/div/div[6]/div[2]/div[3]/div[2]/div/a/span').click()\n",
    "                time.sleep(5)\n",
    "        except Exception as e:\n",
    "            print( str(x) +' '+'store_started')\n",
    "        \n",
    "\n",
    "        time.sleep(10)\n",
    "        html = driver.page_source\n",
    "        bs = BeautifulSoup(html, 'lxml')\n",
    "        reviews = bs.select('li.owAeM') #네이버의 변경부분 반영 \n",
    "\n",
    "        for r in reviews:             \n",
    "            brand = s_brand\n",
    "            store_type = s_type\n",
    "            store_name = s_store\n",
    "            \n",
    "            ## 해당 매장의 검색결과 화면에서, iframe내 값들을 확인 (네이버의 변경부분 반영)\n",
    "            nickname = r.select_one('div.qgLL3>span.P9EZi')\n",
    "            content = r.select_one('div.vg7Fp.CyA_N span.zPfVt')\n",
    "            date = r.select('span.CKUdu>span.place_blind')[1]\n",
    "            revisit = r.select('div.D40bm>span.CKUdu')[1]\n",
    "\n",
    "            # exception handling\n",
    "            nickname = nickname.text if nickname else ''\n",
    "            content = content.text if content else ''\n",
    "            date = date.text if date else ''\n",
    "            revisit = revisit.text if revisit else ''\n",
    "            \n",
    "            # Convert the review date to a datetime object\n",
    "            match = re.search(r'(\\d{4})년 (\\d{1,2})월 (\\d{1,2})일', date)\n",
    "            year, month, day = map(int, match.groups())\n",
    "            formatted_date = f'{year:04d}-{month:02d}-{day:02d}'\n",
    "            review_date = datetime.datetime.strptime(formatted_date, '%Y-%m-%d')\n",
    "\n",
    "            # Check if the review date is after the user-specified date\n",
    "            if review_date >= user_date:\n",
    "                list_sheet.append([brand, store_type, store_name, review_date, nickname, content, revisit])\n",
    "                time.sleep(5)\n",
    "            \n",
    "        # Save the file\n",
    "        # file_name = 'naver_review_' + str(s_store) + '_' + now.strftime('%Y-%m-%d_%H-%M-%S') + '.xlsx'\n",
    "        file_name = 'naver_review_'+ str(s_store) + '.xlsx'\n",
    "        xlsx.save('output/' + file_name)\n",
    "        print( str(x) +' '+'store_finish')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # Save the file(temp)\n",
    "        file_name = 'naver_review_'+ str(s_store) + '.xlsx'\n",
    "        xlsx.save('output/' + file_name)\n",
    "        print( str(x) +' '+'store_finish')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b07a5cc-20f3-4888-afbe-472460b89cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## output 폴더내 생성된 모든 (매장별)엑셀파일을 하나로 합치기 \n",
    " \n",
    "import glob\n",
    "import datetime as dt\n",
    "\n",
    "try:\n",
    "    path = 'output/'\n",
    "    files = glob.glob(path + \"*.xlsx\")\n",
    "    excel = pd.DataFrame()\n",
    "    for file_name in files:\n",
    "        df = pd.read_excel(file_name, sheet_name='output')\n",
    "        #excel = excel.append(df, ignore_index=True)        ## pandas 2.xx 버전 이후에서는 append가 작동하지 않음 \n",
    "        excel = pd.concat([excel, df], ignore_index=True)\n",
    "    #print(excel)\n",
    "    excel.to_excel('concated_file/naver_review_all.xlsx', index=False)\n",
    "    \n",
    "except Exception as ex:\n",
    "    print('error' + str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de117d-5c4f-4fdf-ad0b-0b76c78aed02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
