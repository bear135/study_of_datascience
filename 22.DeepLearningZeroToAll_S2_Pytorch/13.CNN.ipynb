{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "starting-martin",
   "metadata": {},
   "source": [
    "### 13. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-cherry",
   "metadata": {},
   "source": [
    "- 합성곱 \n",
    "\n",
    "<img src = 'img/cnn.png'>\n",
    "\n",
    "- stride : filter를 한번에 얼마나 이동할 것인가? \n",
    "- padding : input의 주변을 특정 값으로 감싼다. (ex. zero-padding =1 : 상하좌우에 0을 한줄씩 추가) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-commodity",
   "metadata": {},
   "source": [
    "- Conv2d 함수의 구조 \n",
    "    - torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride = 1, padding = 0, bias = True/False, padding_mode = 0) \n",
    "        - in_channels / out_channels : input / output 이미지 갯수\n",
    "        - kernel_size : kernel(filter) size \n",
    "\n",
    "<img src = 'img/conv2d.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-tennis",
   "metadata": {},
   "source": [
    "- convolution output의 size \n",
    "\n",
    "<img src = 'img/output_size.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-trinidad",
   "metadata": {},
   "source": [
    "- pooling은 image size를 줄여준다.\n",
    "    - max pooling = 2 : 2x2 매트릭스에서 max값만을 가져온다 (4개 --> 1개로 값 변경)\n",
    "    - average pooling : 2x2 매트릭스에서 평균값만을 가져온다 (4개 --> 1개로 값 변경)\n",
    "    - 주로 max pooling이 사용되며, 함수는 torch.nn.MaxPool2d(kernel_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-hobby",
   "metadata": {},
   "source": [
    "- <font color = 'yellow'> CNN for MNIST code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "excessive-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms \n",
    "import random \n",
    "import matplotlib.pyplot as plt \n",
    "import timeit \n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bottom-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameters \n",
    "training_epochs = 20 \n",
    "batch_size = 100 \n",
    "learning_rate = 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "occupied-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset and DataLoader\n",
    "mnist_train = dsets.MNIST(root = 'MNIST_data/', \n",
    "                          train = True, \n",
    "                          transform = transforms.ToTensor(), \n",
    "                          download = True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root = 'MNIST_data/', \n",
    "                          train = False, \n",
    "                          transform = transforms.ToTensor(), \n",
    "                          download = True)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset = mnist_train, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle = True, \n",
    "                                           drop_last = True ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-poultry",
   "metadata": {},
   "source": [
    "<img src = 'img/cnn_layers.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "behavioral-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model 대산 CNN Model (2 conv layers)을 만든다 \n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        ## layer1: \n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        ## layer2: \n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        # layer2를 거치면 7x7x64를 얻게되고, 이것이 input이 되어 최종 10개(0~9)로 분류되어야 한다. \n",
    "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)   # size(0)는 모른다, 반복 횟수만큼 나열하라는 뜻\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "advised-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model, cost, optimizer \n",
    "model = CNN().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "terminal-richardson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 cost= tensor(0.2254, grad_fn=<AddBackward0>)\n",
      "epoch: 2 cost= tensor(0.0600, grad_fn=<AddBackward0>)\n",
      "epoch: 3 cost= tensor(0.0453, grad_fn=<AddBackward0>)\n",
      "epoch: 4 cost= tensor(0.0355, grad_fn=<AddBackward0>)\n",
      "epoch: 5 cost= tensor(0.0293, grad_fn=<AddBackward0>)\n",
      "epoch: 6 cost= tensor(0.0244, grad_fn=<AddBackward0>)\n",
      "epoch: 7 cost= tensor(0.0204, grad_fn=<AddBackward0>)\n",
      "epoch: 8 cost= tensor(0.0175, grad_fn=<AddBackward0>)\n",
      "epoch: 9 cost= tensor(0.0143, grad_fn=<AddBackward0>)\n",
      "epoch: 10 cost= tensor(0.0131, grad_fn=<AddBackward0>)\n",
      "epoch: 11 cost= tensor(0.0095, grad_fn=<AddBackward0>)\n",
      "epoch: 12 cost= tensor(0.0088, grad_fn=<AddBackward0>)\n",
      "epoch: 13 cost= tensor(0.0089, grad_fn=<AddBackward0>)\n",
      "epoch: 14 cost= tensor(0.0066, grad_fn=<AddBackward0>)\n",
      "epoch: 15 cost= tensor(0.0061, grad_fn=<AddBackward0>)\n",
      "epoch: 16 cost= tensor(0.0046, grad_fn=<AddBackward0>)\n",
      "epoch: 17 cost= tensor(0.0051, grad_fn=<AddBackward0>)\n",
      "epoch: 18 cost= tensor(0.0047, grad_fn=<AddBackward0>)\n",
      "epoch: 19 cost= tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "epoch: 20 cost= tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "Running time : 1156.7377513000001\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "start_time = timeit.default_timer()  ## start time check \n",
    "\n",
    "for epoch in range(training_epochs) : \n",
    "    avg_cost = 0 \n",
    "\n",
    "    for X, Y in data_loader : \n",
    "        #X = X.view(-1, 28*28).to(device)  \n",
    "        X = X.to(device)    #image is already size of (28x28), no reshape need \n",
    "        Y = Y.to(device)\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print('epoch:', epoch+1, 'cost=', avg_cost)\n",
    "\n",
    "\n",
    "end_time = timeit.default_timer()  ## end time check \n",
    "print('Running time :', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "charming-distance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9860000014305115\n"
     ]
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "'''\n",
    "- test 시에는 gradient가 필요 없으믈 torch.no_grad()로 감싸줌\n",
    "- batch 없이 1만개의 데이터 한번에 test\n",
    "- 마찬가지로 to(device)\n",
    "- prediction size [10000, 10]에 대해 argmax (axis = 1)\n",
    "- 모든 test 결과에 대해 평균 .mean(), 값만 빼옴 .item()\n",
    "'''\n",
    "\n",
    "with torch.no_grad():\n",
    "    #X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device) ## 784개를 한줄로 뿌려줌 \n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adopted-understanding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 19.2790 min\n"
     ]
    }
   ],
   "source": [
    "print('Running time: {:.4f}'.format(\n",
    "    (end_time - start_time)/60) + ' min'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-motivation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
