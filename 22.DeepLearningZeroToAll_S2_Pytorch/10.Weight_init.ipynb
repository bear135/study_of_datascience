{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "level-final",
   "metadata": {},
   "source": [
    "### 10. Weight Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-hotel",
   "metadata": {},
   "source": [
    "- weight의 초기화 여부에 따라 모형의 성능이 매우 달라진다. \n",
    "- 모든 초기값을 0으로 하는것은 매우 않좋은 방법이다. (학습 자체가 불가능) \n",
    "- 많이 사용되는 초기화 방법 (weight의 정규분포 또는 uniform 분포를 사용하여 초기화) \n",
    "\n",
    "<img src = 'img/xavier_n_he.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-battle",
   "metadata": {},
   "source": [
    "- xavier_uniform을 통해 초기화한 코드 \n",
    "    - ex> torch.nn.init.normal_(linear1.weight) --> torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "    - 기존 정규분포 초기화 방식에 비해 정확도 향상 확인!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "marked-frederick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 cost= tensor(0.2802, grad_fn=<AddBackward0>)\n",
      "epoch: 2 cost= tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch: 3 cost= tensor(0.0600, grad_fn=<AddBackward0>)\n",
      "epoch: 4 cost= tensor(0.0432, grad_fn=<AddBackward0>)\n",
      "epoch: 5 cost= tensor(0.0316, grad_fn=<AddBackward0>)\n",
      "epoch: 6 cost= tensor(0.0240, grad_fn=<AddBackward0>)\n",
      "epoch: 7 cost= tensor(0.0230, grad_fn=<AddBackward0>)\n",
      "epoch: 8 cost= tensor(0.0196, grad_fn=<AddBackward0>)\n",
      "epoch: 9 cost= tensor(0.0155, grad_fn=<AddBackward0>)\n",
      "epoch: 10 cost= tensor(0.0146, grad_fn=<AddBackward0>)\n",
      "epoch: 11 cost= tensor(0.0119, grad_fn=<AddBackward0>)\n",
      "epoch: 12 cost= tensor(0.0134, grad_fn=<AddBackward0>)\n",
      "epoch: 13 cost= tensor(0.0119, grad_fn=<AddBackward0>)\n",
      "epoch: 14 cost= tensor(0.0116, grad_fn=<AddBackward0>)\n",
      "epoch: 15 cost= tensor(0.0087, grad_fn=<AddBackward0>)\n",
      "Running time : 199.91294390000002\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision.datasets as dsets \n",
    "import torchvision.transforms as transforms \n",
    "import timeit\n",
    "device = 'cpu'\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "## parameters\n",
    "training_epoch = 15 \n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "## dataset \n",
    "mnist_train = dsets.MNIST(root = 'MNIST_data/', \n",
    "                          train = True, \n",
    "                          transform = transforms.ToTensor(), \n",
    "                          download = True )\n",
    "\n",
    "mnist_test = dsets.MNIST(root = 'MNIST_data/', \n",
    "                          train = False, \n",
    "                          transform = transforms.ToTensor(), \n",
    "                          download = True )\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset = mnist_train, \n",
    "                                         batch_size = batch_size, \n",
    "                                         shuffle = True, \n",
    "                                         drop_last = True )\n",
    "\n",
    "## use 3 layers\n",
    "linear1 = torch.nn.Linear(28*28, 256, bias = True)\n",
    "linear2 = torch.nn.Linear(256, 256, bias = True)\n",
    "linear3 = torch.nn.Linear(256, 10, bias = True)\n",
    "\n",
    "## 모형들의 weight를 xavier_uniform 분포로 초기화 \n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)\n",
    "\n",
    "## model, cost function, optimizer \n",
    "## softmax 대신 relu & SGD 대신 Adam 사용 \n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "model = torch.nn.Sequential(linear1, relu, \n",
    "                            linear2, relu, \n",
    "                            linear3, relu).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "total_batch = len(data_loader)\n",
    "\n",
    "start_time = timeit.default_timer()  ## start time check \n",
    "\n",
    "for epoch in range(training_epoch) : \n",
    "    avg_cost = 0 \n",
    "    for X, Y in data_loader : \n",
    "        X = X.view(-1, 28*28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print('epoch:', epoch+1, 'cost=', avg_cost)\n",
    "    \n",
    "terminate_time = timeit.default_timer()  ## end time check\n",
    "print('Running time :', terminate_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naked-conservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "c:\\python\\lib\\site-packages\\torchvision\\datasets\\mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9807999730110168\n",
      "Label:  3\n",
      "Prediction:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-patio",
   "metadata": {},
   "source": [
    "- cf. layer를 5개로 늘여서 좀더 deep하게 해보자 \n",
    "    - cost 감소 & accuracy 개선 확인!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dirty-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 cost= tensor(0.8149, grad_fn=<AddBackward0>)\n",
      "epoch: 2 cost= tensor(0.5345, grad_fn=<AddBackward0>)\n",
      "epoch: 3 cost= tensor(0.5090, grad_fn=<AddBackward0>)\n",
      "epoch: 4 cost= tensor(0.4953, grad_fn=<AddBackward0>)\n",
      "epoch: 5 cost= tensor(0.4883, grad_fn=<AddBackward0>)\n",
      "epoch: 6 cost= tensor(0.4836, grad_fn=<AddBackward0>)\n",
      "epoch: 7 cost= tensor(0.4770, grad_fn=<AddBackward0>)\n",
      "epoch: 8 cost= tensor(0.4798, grad_fn=<AddBackward0>)\n",
      "epoch: 9 cost= tensor(0.4702, grad_fn=<AddBackward0>)\n",
      "epoch: 10 cost= tensor(0.4667, grad_fn=<AddBackward0>)\n",
      "epoch: 11 cost= tensor(0.4696, grad_fn=<AddBackward0>)\n",
      "epoch: 12 cost= tensor(0.4681, grad_fn=<AddBackward0>)\n",
      "epoch: 13 cost= tensor(0.4652, grad_fn=<AddBackward0>)\n",
      "epoch: 14 cost= tensor(0.4669, grad_fn=<AddBackward0>)\n",
      "epoch: 15 cost= tensor(0.4651, grad_fn=<AddBackward0>)\n",
      "Running time : 433.0705700000001\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision.datasets as dsets \n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "device = 'cpu'\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "## parameters\n",
    "training_epoch = 15 \n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "## dataset \n",
    "mnist_train = dsets.MNIST(root = 'MNIST_data/', \n",
    "                          train = True, \n",
    "                          transform = transforms.ToTensor(), \n",
    "                          download = True )\n",
    "\n",
    "mnist_test = dsets.MNIST(root = 'MNIST_data/', \n",
    "                          train = False, \n",
    "                          transform = transforms.ToTensor(), \n",
    "                          download = True )\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset = mnist_train, \n",
    "                                         batch_size = batch_size, \n",
    "                                         shuffle = True, \n",
    "                                         drop_last = True )\n",
    "\n",
    "## use 5 layers & 256 --> 512\n",
    "linear1 = torch.nn.Linear(28*28, 512, bias = True)\n",
    "linear2 = torch.nn.Linear(512, 512, bias = True)\n",
    "linear3 = torch.nn.Linear(512, 512, bias = True)\n",
    "linear4 = torch.nn.Linear(512, 512, bias = True)\n",
    "linear5 = torch.nn.Linear(512, 10, bias = True)\n",
    "\n",
    "## 모형들의 weight를 xavier_uniform 분포로 초기화 \n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)\n",
    "torch.nn.init.xavier_uniform_(linear4.weight)\n",
    "torch.nn.init.xavier_uniform_(linear5.weight)\n",
    "\n",
    "## model, cost function, optimizer \n",
    "## softmax 대신 relu & SGD 대신 Adam 사용 \n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "model = torch.nn.Sequential(linear1, relu, \n",
    "                            linear2, relu, \n",
    "                            linear3, relu, \n",
    "                            linear4, relu, \n",
    "                            linear5, relu).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "total_batch = len(data_loader)\n",
    "\n",
    "start_time = timeit.default_timer()  ## start time check \n",
    "\n",
    "for epoch in range(training_epoch) : \n",
    "    avg_cost = 0 \n",
    "    for X, Y in data_loader : \n",
    "        X = X.view(-1, 28*28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print('epoch:', epoch+1, 'cost=', avg_cost)\n",
    "    \n",
    "terminate_time = timeit.default_timer()  ## end time check\n",
    "print('Running time :', terminate_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "valued-terminal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7930999994277954\n",
      "Label:  5\n",
      "Prediction:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-environment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
