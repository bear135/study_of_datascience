{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### 03. Multivariable Linear Regression\n",
    "    - 3가지 입력값으로 부터 1개의 결과값을 예측하는 문제(다중회귀)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the libaries \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[152.],\n        [185.],\n        [180.],\n        [196.],\n        [142.]])\n"
     ]
    }
   ],
   "source": [
    "## data \n",
    "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
    "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
    "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch    0/1000 | w1: 0.294 | w2: 0.294 | w3: 0.297 | b: 0.003 | cost: 29661.801\n",
      "epoch  100/1000 | w1: 0.674 | w2: 0.661 | w3: 0.676 | b: 0.008 | cost: 1.564\n",
      "epoch  200/1000 | w1: 0.679 | w2: 0.655 | w3: 0.677 | b: 0.008 | cost: 1.498\n",
      "epoch  300/1000 | w1: 0.684 | w2: 0.649 | w3: 0.677 | b: 0.008 | cost: 1.435\n",
      "epoch  400/1000 | w1: 0.689 | w2: 0.643 | w3: 0.678 | b: 0.008 | cost: 1.376\n",
      "epoch  500/1000 | w1: 0.694 | w2: 0.638 | w3: 0.678 | b: 0.009 | cost: 1.320\n",
      "epoch  600/1000 | w1: 0.699 | w2: 0.633 | w3: 0.679 | b: 0.009 | cost: 1.266\n",
      "epoch  700/1000 | w1: 0.704 | w2: 0.627 | w3: 0.679 | b: 0.009 | cost: 1.216\n",
      "epoch  800/1000 | w1: 0.709 | w2: 0.622 | w3: 0.679 | b: 0.009 | cost: 1.168\n",
      "epoch  900/1000 | w1: 0.713 | w2: 0.617 | w3: 0.680 | b: 0.009 | cost: 1.122\n",
      "epoch 1000/1000 | w1: 0.718 | w2: 0.613 | w3: 0.680 | b: 0.009 | cost: 1.079\n"
     ]
    }
   ],
   "source": [
    "## 모형 초기화 \n",
    "w1 = torch.zeros(1, requires_grad = True)\n",
    "w2 = torch.zeros(1, requires_grad = True)\n",
    "w3 = torch.zeros(1, requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "## optimizer \n",
    "optimizer = optim.SGD([w1, w2, w3, b], lr = 0.00001)\n",
    "\n",
    "## model training \n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs+1): \n",
    "    hypothesis = x1_train*w1 + x2_train*w2 + x3_train*w3 + b\n",
    "    cost = torch.mean((hypothesis-y_train)**2)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    ## print the result \n",
    "    if epoch % 100 == 0 : \n",
    "        print(\n",
    "            'epoch {:4d}/{} | w1: {:.3f} | w2: {:.3f} | w3: {:.3f} | b: {:.3f} | cost: {:.3f}'.format(\n",
    "                epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item() \n",
    "            )\n",
    "        )"
   ]
  },
  {
   "source": [
    "- 위의 코드를 좀더 간략하게 만들어 보자. \n",
    "    - train x1, x2, x3를 하나의 matrix로 만들고, matmul을 이용하여 계산한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\nEpoch    1/20 hypothesis: tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]) Cost: 9298.520508\nEpoch    2/20 hypothesis: tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]) Cost: 2915.712402\nEpoch    3/20 hypothesis: tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]) Cost: 915.040649\nEpoch    4/20 hypothesis: tensor([137.7967, 165.6247, 163.1911, 177.7112, 126.3307]) Cost: 287.936157\nEpoch    5/20 hypothesis: tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]) Cost: 91.371010\nEpoch    6/20 hypothesis: tensor([148.1035, 178.0143, 175.3980, 191.0042, 135.7812]) Cost: 29.758249\nEpoch    7/20 hypothesis: tensor([150.1744, 180.5042, 177.8509, 193.6753, 137.6805]) Cost: 10.445281\nEpoch    8/20 hypothesis: tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]) Cost: 4.391237\nEpoch    9/20 hypothesis: tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]) Cost: 2.493121\nEpoch   10/20 hypothesis: tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]) Cost: 1.897688\nEpoch   11/20 hypothesis: tensor([152.5485, 183.3609, 180.6640, 196.7389, 139.8602]) Cost: 1.710555\nEpoch   12/20 hypothesis: tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]) Cost: 1.651412\nEpoch   13/20 hypothesis: tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]) Cost: 1.632369\nEpoch   14/20 hypothesis: tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]) Cost: 1.625924\nEpoch   15/20 hypothesis: tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]) Cost: 1.623420\nEpoch   16/20 hypothesis: tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]) Cost: 1.622141\nEpoch   17/20 hypothesis: tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]) Cost: 1.621262\nEpoch   18/20 hypothesis: tensor([152.7999, 183.6688, 180.9644, 197.0661, 140.0963]) Cost: 1.620501\nEpoch   19/20 hypothesis: tensor([152.8014, 183.6715, 180.9665, 197.0686, 140.0985]) Cost: 1.619764\nEpoch   20/20 hypothesis: tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.0999]) Cost: 1.619046\n"
     ]
    }
   ],
   "source": [
    "## data를 좀더 간략하게 \n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "## 모형 초기화, optimizer 설정도 간략하게 가능 \n",
    "w = torch.zeros((3,1), requires_grad = True)  ## w는 3x1의 매트릭스 \n",
    "b = torch.zeros(1, requires_grad = True)      ## b는 1의 매트릭스\n",
    "optimizer = optim.SGD([w, b], lr= 0.00001)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1): \n",
    "    hypothesis = x_train.matmul(w)+b    ##모형을 간략하게 표현 \n",
    "    cost = torch.mean((hypothesis-y_train)**2)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    ## print the result (if문 사용할 필요 없음))\n",
    "    ## hypothesis 출력을 깨끗하게 하기 위해, squeeze(세로행렬을 가로 변환) 와 detach(불필요한 정보 삭제) 사용    \n",
    "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "    ))   "
   ]
  },
  {
   "source": [
    "- 실전에서 쓰이는 코드 \n",
    "    - torch.nn, torch.nn.functional 모듈을 사용하여 코드를 간단하게 만든다. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input = 3 & output = 1을 처리하는 모델을 class로 선언한다. \n",
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/20 Cost: 7561.7314\nEpoch    1/20 Cost: 2371.3164\nEpoch    2/20 Cost: 744.3956\nEpoch    3/20 Cost: 234.4428\nEpoch    4/20 Cost: 74.5989\nEpoch    5/20 Cost: 24.4958\nEpoch    6/20 Cost: 8.7907\nEpoch    7/20 Cost: 3.8676\nEpoch    8/20 Cost: 2.3239\nEpoch    9/20 Cost: 1.8395\nEpoch   10/20 Cost: 1.6873\nEpoch   11/20 Cost: 1.6391\nEpoch   12/20 Cost: 1.6235\nEpoch   13/20 Cost: 1.6182\nEpoch   14/20 Cost: 1.6160\nEpoch   15/20 Cost: 1.6149\nEpoch   16/20 Cost: 1.6140\nEpoch   17/20 Cost: 1.6133\nEpoch   18/20 Cost: 1.6126\nEpoch   19/20 Cost: 1.6120\nEpoch   20/20 Cost: 1.6113\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "## class에서 정의한 모델을 사용함 \n",
    "model = MultivariateLinearRegressionModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr= 1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):     \n",
    "    ## 모델을 사용하여 데이터를 훈련시켜라 \n",
    "    prediction = model(x_train)\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch {:4d}/{} Cost: {:.4f}'.format(\n",
    "        epoch, nb_epochs, cost.item()\n",
    "    ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Final Result\n1. Weights & bias: tensor([152.7227, 183.7155, 180.8768, 197.1936, 140.0789])\n2. Cost: tensor(1.6113)\n"
     ]
    }
   ],
   "source": [
    "print('Final Result')\n",
    "print('1. Weights & bias:', prediction.squeeze().detach())\n",
    "print('2. Cost:', cost.detach())"
   ]
  },
  {
   "source": [
    "- 참고) 데이터를 load하여 모델 훈련 시키기 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 73.  80.  75. 152.]\n [ 93.  88.  93. 185.]\n [ 89.  91.  90. 180.]\n [ 96.  98. 100. 196.]\n [ 73.  66.  70. 142.]]\n(25, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "xy = np.loadtxt('data/data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "print(xy[:5])\n",
    "print(xy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 73.  80.  75.]\n [ 93.  88.  93.]\n [ 89.  91.  90.]\n [ 96.  98. 100.]\n [ 73.  66.  70.]]\n[[152.]\n [185.]\n [180.]\n [196.]\n [142.]]\n"
     ]
    }
   ],
   "source": [
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]  ## y_data = xy[:, -1]이 아님에 주의!!\n",
    "print(x_data[:5])\n",
    "print(y_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/21 Cost: 20543.7500\nEpoch    1/21 Cost: 7601.6450\nEpoch    2/21 Cost: 2816.5884\nEpoch    3/21 Cost: 1047.4189\nEpoch    4/21 Cost: 393.3061\nEpoch    5/21 Cost: 151.4607\nEpoch    6/21 Cost: 62.0419\nEpoch    7/21 Cost: 28.9792\nEpoch    8/21 Cost: 16.7532\nEpoch    9/21 Cost: 12.2309\nEpoch   10/21 Cost: 10.5571\nEpoch   11/21 Cost: 9.9363\nEpoch   12/21 Cost: 9.7049\nEpoch   13/21 Cost: 9.6174\nEpoch   14/21 Cost: 9.5832\nEpoch   15/21 Cost: 9.5687\nEpoch   16/21 Cost: 9.5614\nEpoch   17/21 Cost: 9.5568\nEpoch   18/21 Cost: 9.5532\nEpoch   19/21 Cost: 9.5501\nEpoch   20/21 Cost: 9.5470\nEpoch   21/21 Cost: 9.5440\n"
     ]
    }
   ],
   "source": [
    "## numpy arrary를 tensor로써 가져온다. \n",
    "x_data_train = torch.FloatTensor(x_data)\n",
    "y_data_train = torch.FloatTensor(y_data)\n",
    "\n",
    "model = MultivariateLinearRegressionModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr= 1e-5)\n",
    "\n",
    "nb_epochs = 21\n",
    "for epoch in range(nb_epochs+1):     \n",
    "    prediction = model(x_data_train)\n",
    "    cost = F.mse_loss(prediction, y_data_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch {:4d}/{} Cost: {:.4f}'.format(\n",
    "        epoch, nb_epochs, cost.item()\n",
    "    ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Final Result\n1. Weights & bias: tensor([[155.1230],\n        [183.3790],\n        [182.2354],\n        [199.1230],\n        [138.5018],\n        [102.6612],\n        [150.8056],\n        [114.3663],\n        [171.4164],\n        [159.8771],\n        [143.7053],\n        [140.5620],\n        [187.5747],\n        [154.7676],\n        [151.1049],\n        [186.9828],\n        [145.6467],\n        [182.1534],\n        [179.1929],\n        [160.7616],\n        [176.2131],\n        [172.8384],\n        [168.0769],\n        [154.7841],\n        [190.2478]])\n2. Cost: tensor(9.5440)\n"
     ]
    }
   ],
   "source": [
    "print('Final Result')\n",
    "print('1. Weights & bias:', prediction.detach())\n",
    "print('2. Cost:', cost.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}