{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accompanied-netherlands",
   "metadata": {},
   "source": [
    "### 09. ReLu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-trigger",
   "metadata": {},
   "source": [
    "- sigmoid는 양 끝쪽의 미분값(gradient) 값이 너무 작아, 역전파시 사라지게 된다. \n",
    "- ReLu는 f(x) = (0, 1) 즉 기울기가 존재하면 무조건 1을 출력한다. \n",
    "\n",
    "<img src = 'img/ReLu.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-jefferson",
   "metadata": {},
   "source": [
    "- torch.optim 모듈은 아래와 같이 다양한 최적화 알고리즘들을 지원한다. \n",
    "- https://pytorch.org/docs/master/optim.html#torch-optim\n",
    "\n",
    "<img src = 'img/optim.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-intention",
   "metadata": {},
   "source": [
    "- function = ReLu & optimizer = Adam 알고리즘을 사용한 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "postal-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 cost= tensor(79.4762, grad_fn=<AddBackward0>)\n",
      "epoch: 2 cost= tensor(2.3860, grad_fn=<AddBackward0>)\n",
      "epoch: 3 cost= tensor(2.2885, grad_fn=<AddBackward0>)\n",
      "epoch: 4 cost= tensor(2.2383, grad_fn=<AddBackward0>)\n",
      "epoch: 5 cost= tensor(2.2185, grad_fn=<AddBackward0>)\n",
      "epoch: 6 cost= tensor(2.1947, grad_fn=<AddBackward0>)\n",
      "epoch: 7 cost= tensor(2.1617, grad_fn=<AddBackward0>)\n",
      "epoch: 8 cost= tensor(2.1095, grad_fn=<AddBackward0>)\n",
      "epoch: 9 cost= tensor(2.0654, grad_fn=<AddBackward0>)\n",
      "epoch: 10 cost= tensor(2.0377, grad_fn=<AddBackward0>)\n",
      "epoch: 11 cost= tensor(2.0339, grad_fn=<AddBackward0>)\n",
      "epoch: 12 cost= tensor(2.0506, grad_fn=<AddBackward0>)\n",
      "epoch: 13 cost= tensor(2.0072, grad_fn=<AddBackward0>)\n",
      "epoch: 14 cost= tensor(2.0092, grad_fn=<AddBackward0>)\n",
      "epoch: 15 cost= tensor(2.0068, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision.datasets as dsets \n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "device = 'cpu'\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "## parameters\n",
    "training_epoch = 15 \n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "## dataset \n",
    "mnist_train = dsets.MNIST(root = 'MNIST_data/', \n",
    "                          train = True, \n",
    "                          transform = transforms.ToTensor(), \n",
    "                          download = True )\n",
    "\n",
    "mnist_test = dsets.MNIST(root = 'MNIST_data/', \n",
    "                          train = False, \n",
    "                          transform = transforms.ToTensor(), \n",
    "                          download = True )\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset = mnist_train, \n",
    "                                         batch_size = batch_size, \n",
    "                                         shuffle = True, \n",
    "                                         drop_last = True )\n",
    "\n",
    "## use 3 layers\n",
    "linear1 = torch.nn.Linear(28*28, 256, bias = True)\n",
    "linear2 = torch.nn.Linear(256, 256, bias = True)\n",
    "linear3 = torch.nn.Linear(256, 10, bias = True)\n",
    "\n",
    "## 모형들의 weight를 정규분포로 초기화 \n",
    "torch.nn.init.normal_(linear1.weight)\n",
    "torch.nn.init.normal_(linear2.weight)\n",
    "torch.nn.init.normal_(linear3.weight)\n",
    "\n",
    "## model, cost function, optimizer \n",
    "## softmax 대신 relu & SGD 대신 Adam 사용 \n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "model = torch.nn.Sequential(linear1, relu, \n",
    "                            linear2, relu, \n",
    "                            linear3, relu).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "total_batch = len(data_loader)\n",
    "\n",
    "for epoch in range(training_epoch) : \n",
    "    avg_cost = 0 \n",
    "    for X, Y in data_loader : \n",
    "        X = X.view(-1, 28*28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print('epoch:', epoch+1, 'cost=', avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriental-friendly",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "c:\\python\\lib\\site-packages\\torchvision\\datasets\\mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.249099999666214\n",
      "Label:  1\n",
      "Prediction:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-craft",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-study",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
